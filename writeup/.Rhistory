data(package = .packages(all.available = TRUE))
# I recommend "pacman" for managing add-on packages. It will
# install packages, if needed, and then load the packages.
install.packages("pacman")
library(pacman)  # No message.
library(datasets)  # Load/unload base packages manually
head(iris)
plot(iris$Species)  # Categorical variable
plot(iris$Petal.Length)  # Quantitative variable
plot(iris$Species, iris$Petal.Width)  # Cat x quant
plot(iris)  # Entire data frame
# Plot with options
plot(iris$Petal.Length, iris$Petal.Width,
col = "#cc0000",  # Hex code for datalab.cc red
pch = 19,         # Use solid circles for points
main = "Iris: Petal Length vs. Petal Width",
xlab = "Petal Length",
ylab = "Petal Width")
plot(cos, 0, 2*pi)
plot(exp, 1, 5)
plot(dnorm, -3, +3)
# Formula plot with options
plot(dnorm, -3, +3,
col = "#cc0000",
lwd = 5,
main = "Standard Normal Distribution",
xlab = "z-scores",
ylab = "Density")
# Clear packages
detach("package:datasets", unload = TRUE)
# Clear console
cat("\014")  # ctrl+L
library(datasets)
head(mtcars)
?mtcars
barplot(mtcars$cyl)             # Doesn't work
# Need a table with frequencies for each category
cylinders <- table(mtcars$cyl)  # Create table
barplot(cylinders)              # Bar chart
plot(cylinders)                 # Default X-Y plot (lines)
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load/unload base packages manually
head(mtcars)
hist(mtcars$mpg)
hist(mtcars$mpg)
# Good to first check univariate distributions
hist(mtcars$wt)
# Basic X-Y plot for two quantitative variables
plot(mtcars$wt, mtcars$mpg)
# Add some options
plot(mtcars$wt, mtcars$mpg,
pch = 19,         # Solid circle
cex = 1.5,        # Make 150% size
col = "#cc0000",  # Red
main = "MPG as a Function of Weight of Cars",
xlab = "Weight (in 1000 pounds)",
ylab = "MPG")
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load/unload base packages manually
head(iris)
summary(iris$Species)       # Categorical variable
summary(iris$Sepal.Length)  # Quantitative variable
summary(iris)               # Entire data frame
# Clear console
cat("\014")  # ctrl+L
library(datasets)  # Load base packages manually
# Installs pacman ("package manager") if needed
if (!require("pacman")) install.packages("pacman")
head(iris)
# Get info on package
p_help(psych)           # Opens package PDF in browser
describe(iris$Sepal.Length)  # One quantitative variable
library(datasets)  # Load/unload base packages manually
head(iris)
summary(iris$Species)  # Get names and n for each species
# Virginica
hist(iris$Petal.Length[iris$Species == "virginica"],
main = "Petal Length: Virginica")
# Short petals only (all Setosa)
hist(iris$Petal.Length[iris$Petal.Length < 2],
main = "Petal Length < 2")
("hello world")
print("hello world")
print("hello world")
print("This is for problem set 1 for PSYCH 251")
mtcars
mtcars$mpg |> mean()
round(mean(gpm(mtcars$mpg)), digits = 2)
library(tidyverse)
round(mean(gpm(mtcars$mpg)), digits = 2)
library(tidyverse)
library(tidyverse)
mtcars
round(mean(gpm(mtcars$mpg)), digits = 2)
round(mean(gpm(mtcars$mpg)), digits = 2)
library(tidyverse)
mtcars
sgf <- read_csv("stiller_scales_data.csv")
#library(tidyr)
#library(dplyr)
#library(ggplot2)
library(tidyr)
library(dplyr)
library(ggplot2)
setwd("~/Desktop")
data <- read.csv("Realistic Threat and Asian Americans.csv", header=TRUE)
setwd("~/Desktop")
# Import data
data <- read.csv("Realistic Threat and Asian Americans.csv", header=TRUE)
setwd("~/Desktop/maddux2008/writeup")
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE)
# Prepare data for analysis - create columns etc.
#data_long %>%
# pivot_longer(cols=-c("id"),
#            names_to='Measurement',
#           values_to='Value')
# need to create a column/variable for the condition participants are in
```
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE)
filtered_data = d %>%
filter(rowSums(is.na(data) > 6))
View(data)
View(data)
filtered_data = data %>%
filter(rowSums(is.na(data) > 6))
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
header(data)
headers(data)
colnames(data)
# Remove unwanted columns
data <- data[, -c(1:17)] # delete columns 1 through 17
colnames(data)
data <- data[, -c(16:19)] # then, delete columns 16 through 19
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
colnames(data)
# Remove unwanted columns
data <- data[, -c(1:8)] # delete columns 1 through 8
colnames(data)
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
filtered_data = data %>%
filter(rowSums(is.na(data) >= 7))
colnames(data)
# Convert from chr to int
data[4, 15:17] <- lapply(data[4, 15:17], as.numeric)
View(data)
# Convert from chr to int
data <- lapply(data[4, 15:17], as.numeric)
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
# Convert from chr to int
data[4, 15:17] <- lapply(data[4, 15:17], as.numeric)
# Convert from chr to int
data[4] <- lapply(data[4], as.numeric)
data[15:17] <- lapply(data[15:17], as.numeric)
filtered_data = data %>%
filter(rowSums(is.na(data) >= 7))
filtered_data = data %>%
filter(rowSums(is.na(data) > 7))
data_long %>%
pivot_longer(cols=-c("ResponseID"),
names_to='Measurement',
values_to='Value')
data %>%
pivot_longer(cols=-c("ResponseID"),
names_to='Measurement',
values_to='Value')
data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
data <- data[, -c(2)] # then, delete the new column 2
data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
data <- lapply(data, as.character()
colnames(data)
colnames(data)
data <- lapply(data, as.character())
data <- lapply(data, as.character)
data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
data[4] <- lapply(data[4], as.numeric)
data[15:17] <- lapply(data[15:17], as.numeric)
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
View(data)
data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
data_long <- data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
View(data_long)
View(data_long)
View(data)
# Remove unwanted columns and rows
data <- data[-c(2)]
View(data)
View(data)
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns and rows
data <- data[-c(2),] # delete row 2
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
data_long <- data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
View(data_long)
data <- data[-c(:2),] # delete row 2
# Remove unwanted columns and rows
data <- data[-c(1:2),] # delete row 2
data_long <- data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
filtered_data = data %>%
filter(rowSums(is.na(data) >= 7))
# Data exclusion / filtering
# Filter out people who did not answer 7 or more questions (half or more)
rowSums(is.na(data))
# Data exclusion / filtering
# Filter out people who did not answer 7 or more questions (half or more)
total_na <- rowSums(is.na(data))
if (total_na >= 7) {
return (TRUE)
if (total_na >= 7) {
return (TRUE)
realistic_threat_long_d %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
realistic_threat_long_d %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
realistic_threat_long_d %>%
group_by(Condition) %>%
realistic_threat_long_d %>%
group_by(Condition)
realistic_threat_long_d = realistic_threat_long_d %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
realistic_threat_long_d = data_long %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
# Rename 1 and 2 in condition to no threat and threat
data$[data$Condition == "1"] <- "No Threat"
# Rename 1 and 2 in condition to no threat and threat
data$Condition[data$Condition == "1"] <- "No Threat"
data$Condition[data$Condition == "2"] <- "Threat"
data_long = data_long %>%
mutate(Condition = ifelse(Measurement=="No Threat", "No Threat",
ifelse(Measurement=="Threat", "Threat",)))
data_long = data_long %>%
mutate(Condition = ifelse(Measurement=="No Threat", "No Threat",
ifelse(Measurement=="Threat", "Threat", "NA")))
data_long = data_long %>%
mutate(Condition = ifelse(Value=="No Threat", "No Threat",
ifelse(Value=="Threat", "Threat", "NA")))
data_long <- data %>%
pivot_longer(cols=-c("ResponseId"),
names_to='Measurement',
values_to='Value')
data_long = data_long %>%
mutate(Condition = ifelse(Value=="No Threat", "No Threat",
ifelse(Value=="Threat", "Threat", "NA")))
data_long = data_long %>%
mutate(Condition = ifelse(Value=="No Threat", "No Threat",
ifelse(Value=="Threat", "Threat", NA)))
realistic_threat_long_d = data_long %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
realistic_threat_long_d = data_long %>%
group_by(Condition) %>%
summarize(AvgThreat = mean(realisticThreatQ_1, na.rm=T))
library(tidyr)
library(dplyr)
library(ggplot2)
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns and rows
data <- data[-c(1:2),] # delete rows 1 and 2
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
library(effectsize)
View(data)
View(data)
t.test(realisticThreatQ_1 ~ Condition, data=data)
# Convert from chr to int
data[4] <- lapply(data[4], as.numeric)
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns and rows
data <- data[-c(1:2),] # delete rows 1 and 2
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
data[3] <- lapply(data[3], as.numeric)
colnames(data)
data[14:16] <- lapply(data[14:16], as.numeric)
t.test(realisticThreatQ_1 ~ Condition, data=data)
cohens_d(realisticThreatQ_1 ~ Condition, data=data)
data %>%
group_by(Condition) %>%
summarise(M = mean(realisticThreatQ_1), SD = sd(realisticThreatQ_1), count = n()) -> mean_threat
t.test(realisticThreatQ_1 ~ Condition, data=data)
cohens_d(realisticThreatQ_1 ~ Condition, data=data)
t.test(attitude_1 ~ Condition, data=data)
cohens_d(attitude_1 ~ Condition, data=data)
data %>%
group_by(Condition) %>%
summarise(M = mean(attitude_1), SD = sd(attitude_1), count = n()) -> mean_attitude
t.test(emotion ~ Condition, data=data)
cohens_d(emotion ~ Condition, data=data)
data %>%
group_by(Condition) %>%
summarise(M = mean(emotion), SD = sd(emotion), count = n()) -> mean_emotion
data$Condition[data$Condition == "1"] <- "No Threat"
data$Condition[data$Condition == "2"] <- "Threat"
ggplot(data = mean_attitude, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="grey") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(1,7)) +
ylab("Mean Attitude") +
xlab("Threat Condition") +
theme_minimal()
data %>%
group_by(Condition) %>%
summarise(M = mean(attitude_1), SD = sd(attitude_1), count = n()) -> mean_attitude
ggplot(data = mean_attitude, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="grey") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(1,7)) +
ylab("Mean Attitude") +
xlab("Threat Condition") +
theme_minimal()
ggplot(data = mean_attitude, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="black") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(1,7)) +
ylab("Mean Attitude") +
xlab("Threat Condition") +
theme_minimal()
ggplot(data = mean_emotion, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="grey") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(0,10)) +
ylab("Mean Affect") +
xlab("Threat Condition") +
theme_minimal()
t.test(realisticThreatQ_1 ~ Condition, data=data)
cohens_d(realisticThreatQ_1 ~ Condition, data=data)
View(data)
# Import data
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns and rows
data <- data[-c(1:2),] # delete rows 1 and 2
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
View(mean_threat)
data$Condition[data$Condition == "1"] <- "No Threat"
data$Condition[data$Condition == "2"] <- "Threat"
data[3] <- lapply(data[3], as.numeric)
data[14:16] <- lapply(data[14:16], as.numeric)
# The original paper did ANOVA instead of t-tests, but honestly I'm kind of confused as to why they did since there are only two samples to compare. I'm also planning on coming to office hours to talk about this, maybe there's something I'm missing, but I struggled to run the ANOVAs because of this, so for this assignment, I ran two sample t-tests instead, if that's okay! I still wanted to have some type of result to show you guys.
# Two-sample t-test on perceived realistic threat
t.test(realisticThreatQ_1 ~ Condition, data=data)
t.test(attitude_1 ~ Condition, data=data)
data <- read.csv("Realistic Threat and Asian Americans Pilot Data.csv", header=TRUE, na.strings=c(""," ","NA"))
# Remove unwanted columns and rows
data <- data[-c(1:2),] # delete rows 1 and 2
data <- data[, -c(1:8)] # delete columns 1 through 8
data <- data[, -c(2:9, 25:27)] # then, delete columns 2 through 9
data <- data[, -c(2)] # then, delete the new column 2
# Sorry I know there's a much more efficient way to do this
data[3] <- lapply(data[3], as.numeric)
data[14:16] <- lapply(data[14:16], as.numeric)
data$Condition[data$Condition == "1"] <- "No Threat"
data$Condition[data$Condition == "2"] <- "Threat"
t.test(realisticThreatQ_1 ~ Condition, data=data)
cohens_d(realisticThreatQ_1 ~ Condition, data=data)
pwr.t.test(n= NULL, d = 0.5, sig.level = 0.05, power = 0.8, type = "two.sample", alternative = "two.sided")
library(effectsize)
library(pwr)
pwr.t.test(n= NULL, d = 0.5, sig.level = 0.05, power = 0.8, type = "two.sample", alternative = "two.sided")
pwr.t.test(n= NULL, d = 0.5, sig.level = 0.05, power = 0.8, type = "two.sample")
pwr.t.test(n= NULL, d = 0.5, sig.level = 0.05, power = 0.8, type = "two.sample")
ggplot(data = mean_emotion, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="grey") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(0,10)) +
ylab("Mean Affect") +
xlab("Threat Condition") +
theme_minimal()
ggplot(data = mean_attitude, aes(x = Condition, y = M, ymin = M-SD, ymax= M+SD)) +
geom_bar(stat = "identity", width = 0.5, fill="grey") +
geom_errorbar(width = 0.05) +
coord_cartesian(ylim = c(1,7)) +
ylab("Mean Attitude") +
xlab("Threat Condition") +
theme_minimal()
